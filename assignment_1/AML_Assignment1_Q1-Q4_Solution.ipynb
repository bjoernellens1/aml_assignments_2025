{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Assignment 1 \u2014 Statistical Learning Foundations\n", "Advanced Machine and Deep Learning (WS 25/26)\n", "\n", "This notebook contains complete solutions for Q1\u2013Q4. Each section mirrors the assignment wording and includes the requested plots and metrics. I kept the code explicit and commented so it\u2019s easy to follow or adapt."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Environment & Imports\n", "We use only standard scientific Python libraries. Plots are made with matplotlib (one chart per figure, default styles)."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "from typing import Tuple, Dict\n", "\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.metrics import mean_squared_error\n", "from sklearn.linear_model import Ridge, Lasso\n", "from sklearn.datasets import fetch_california_housing, make_regression\n", "\n", "np.random.seed(42)\n", "plt.rcParams['figure.figsize'] = (7, 4)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---\n", "## Q1. Estimators \u2014 Sample Mean Convergence\n", "**Task:** Generate samples $x_i \\sim \\mathcal N(0,1)$ for $n \\in \\{10, 100, 1000, 10000, 100000\\}$ and plot how the sample mean changes as $n$ increases. Include the true mean as a horizontal line."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["ns = [10, 100, 1000, 10000, 100000]\n", "sample_means = []\n", "for n in ns:\n", "    x = np.random.randn(n)\n", "    sample_means.append(np.mean(x))\n", "sample_means = np.array(sample_means)\n", "\n", "plt.figure()\n", "plt.plot(ns, sample_means, marker='o')\n", "plt.axhline(0.0)\n", "plt.xscale('log')\n", "plt.xlabel('n (log scale)')\n", "plt.ylabel('sample mean')\n", "plt.title('Sample mean vs. n for N(0,1)')\n", "plt.show()\n", "\n", "for n, m in zip(ns, sample_means):\n", "    print(f\"n={n:6d} -> sample mean = {m:+.6f}\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---\n", "## Q2. Regression with Gaussian Noise (MLE)\n", "Model: $y_i = x_i^\\top \\theta + \\varepsilon_i$, with $\\varepsilon_i \\sim \\mathcal N(0,\\sigma^2)$. For this model,\n", "$$\\hat\\theta = (X^\\top X)^{-1} X^\\top y,$$\n", "after standardizing input features (not the target). We:\n", "1. Load **CaliforniaHousing** (with an offline fallback if needed).\n", "2. Standardize features.\n", "3. Fit the closed-form linear model.\n", "4. Report training and testing MSE.\n", "5. Plot a **learning curve** (train/test MSE vs. training fraction).\n", "6. Verify the **MLE\u2013MSE equivalence** by comparing per-sample NLL and MSE using a fixed $\\hat\\sigma^2$ from the full training residuals."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["def load_california_or_synthetic(random_state: int = 42) -> Tuple[np.ndarray, np.ndarray, Dict]:\n", "    \"\"\"Try CaliforniaHousing; if unavailable, use a synthetic regression dataset of same shape.\n", "    Returns X, y, meta with feature_names and source tag.\n", "    \"\"\"\n", "    try:\n", "        data = fetch_california_housing()\n", "        X = data.data\n", "        y = data.target\n", "        meta = {\"source\": \"CaliforniaHousing\", \"feature_names\": list(data.feature_names)}\n", "        return X, y, meta\n", "    except Exception:\n", "        # Synthetic fallback: same n_samples and n_features; scale y to ~[0,5]\n", "        X, y = make_regression(n_samples=20640, n_features=8, noise=12.0, random_state=random_state)\n", "        y = (y - y.min()) / (y.max() - y.min()) * 5.0\n", "        meta = {\"source\": \"SyntheticFallback\", \"feature_names\": [f\"f{i}\" for i in range(8)]}\n", "        return X, y, meta\n", "\n", "X, y, meta = load_california_or_synthetic()\n", "X.shape, y.shape, meta\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Q2(a). Closed-form fit with standardized inputs\n", "We split into train/test (80/20), standardize inputs using `StandardScaler` (fitted on train only), compute the closed-form solution, and report MSE."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n", "scaler = StandardScaler().fit(X_train)\n", "Xs_train = scaler.transform(X_train)\n", "Xs_test = scaler.transform(X_test)\n", "\n", "def add_intercept(A: np.ndarray) -> np.ndarray:\n", "    return np.hstack([np.ones((A.shape[0], 1)), A])\n", "\n", "def closed_form_theta(Xs: np.ndarray, y: np.ndarray) -> np.ndarray:\n", "    Xb = add_intercept(Xs)\n", "    theta = np.linalg.pinv(Xb.T @ Xb) @ (Xb.T @ y)\n", "    return theta\n", "\n", "theta_cf = closed_form_theta(Xs_train, y_train)\n", "\n", "def predict_theta(theta: np.ndarray, Xs: np.ndarray) -> np.ndarray:\n", "    return add_intercept(Xs) @ theta\n", "\n", "y_pred_train = predict_theta(theta_cf, Xs_train)\n", "y_pred_test = predict_theta(theta_cf, Xs_test)\n", "mse_train = mean_squared_error(y_train, y_pred_train)\n", "mse_test = mean_squared_error(y_test, y_pred_test)\n", "\n", "print(f\"Source: {meta['source']}\")\n", "print(f\"Training MSE: {mse_train:.6f}\")\n", "print(f\"Testing  MSE: {mse_test:.6f}\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Q2(b). Learning curve (train/test MSE vs. training fraction)\n", "We randomly shuffle the training data, then train on fractions from 10% to 100% and compute train/test MSE for each fraction."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["fractions = np.linspace(0.1, 1.0, 10)\n", "idx = np.random.permutation(len(Xs_train))\n", "\n", "mse_tr_curve, mse_te_curve = [], []\n", "for f in fractions:\n", "    k = max(2, int(len(Xs_train) * f))\n", "    X_sub = Xs_train[idx[:k]]\n", "    y_sub = y_train[idx[:k]]\n", "    th = closed_form_theta(X_sub, y_sub)\n", "    mse_tr_curve.append(mean_squared_error(y_sub, predict_theta(th, X_sub)))\n", "    mse_te_curve.append(mean_squared_error(y_test, predict_theta(th, Xs_test)))\n", "\n", "plt.figure()\n", "plt.plot(fractions, mse_tr_curve, marker='o', label='Train MSE')\n", "plt.plot(fractions, mse_te_curve, marker='s', label='Test MSE')\n", "plt.xlabel('Training fraction')\n", "plt.ylabel('MSE')\n", "plt.title('Learning curve: MSE vs. training fraction')\n", "plt.legend()\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Q2(c). Verify MLE\u2013MSE equivalence\n", "We first estimate a fixed variance $\\hat\\sigma^2$ from the residuals of the **full training set** model (using all training data), then for each training fraction compute the **per-sample** Gaussian NLL and MSE. Since\n", "$$\\text{NLL}(\\theta) = \\frac{1}{2\\hat\\sigma^2} \\sum_i (y_i - x_i^\\top\\theta)^2 + \\text{const},$$\n", "the two curves should have the same shape, differing only by a scale factor.\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Fixed sigma^2 from full training residuals\n", "res_full = y_train - predict_theta(theta_cf, Xs_train)\n", "sigma2_hat = float(np.var(res_full, ddof=1))  # unbiased estimate\n", "print(f\"Estimated sigma^2 from full training residuals: {sigma2_hat:.6f}\")\n", "\n", "per_sample_mse = []\n", "per_sample_nll = []\n", "for f, mse_tr in zip(fractions, mse_tr_curve):\n", "    # per-sample MSE is already mean of squared residuals\n", "    per_sample_mse.append(mse_tr)\n", "    # per-sample NLL (ignoring constants): (1/(2*sigma^2)) * MSE\n", "    per_sample_nll.append(0.5 * mse_tr / sigma2_hat)\n", "\n", "plt.figure()\n", "plt.plot(fractions, per_sample_mse, marker='o', label='Per-sample MSE')\n", "plt.plot(fractions, per_sample_nll, marker='s', label='Per-sample NLL (scaled MSE)')\n", "plt.xlabel('Training fraction')\n", "plt.ylabel('Value (arbitrary scale)')\n", "plt.title('MSE vs. NLL (fixed sigma^2): identical shapes up to scale')\n", "plt.legend()\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---\n", "## Q3. MAP Estimation & Regularization \u2014 Ridge vs. Lasso\n", "Under a Gaussian prior $\\theta \\sim \\mathcal N(0, \\tau^2 I)$, the MAP solution adds an L2 penalty (Ridge) with $\\lambda = \\sigma^2/\\tau^2$. With a Laplace prior, the MAP solution adds an L1 penalty (Lasso).\n", "\n", "**Task:** Standardize inputs, keep target unchanged. For $\\lambda \\in \\{10^{-6},10^{-5},\\dots,10^{3}\\}$, fit Ridge and Lasso and compute **training** and **testing** **RMSE** for each $\\lambda$. We report results and plot RMSE vs. $\\log_{10} \\lambda$. "]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["lambdas = np.array([10.0**k for k in range(-6, 4)])  # 1e-6 ... 1e3\n", "\n", "ridge_train_rmse, ridge_test_rmse = [], []\n", "lasso_train_rmse, lasso_test_rmse = [], []\n", "\n", "for lam in lambdas:\n", "    # Ridge\n", "    ridge = Ridge(alpha=lam)\n", "    ridge.fit(Xs_train, y_train)\n", "    r_tr = np.sqrt(mean_squared_error(y_train, ridge.predict(Xs_train)))\n", "    r_te = np.sqrt(mean_squared_error(y_test, ridge.predict(Xs_test)))\n", "    ridge_train_rmse.append(r_tr)\n", "    ridge_test_rmse.append(r_te)\n", "\n", "    # Lasso (increase max_iter for stability)\n", "    lasso = Lasso(alpha=lam, max_iter=20000)\n", "    lasso.fit(Xs_train, y_train)\n", "    l_tr = np.sqrt(mean_squared_error(y_train, lasso.predict(Xs_train)))\n", "    l_te = np.sqrt(mean_squared_error(y_test, lasso.predict(Xs_test)))\n", "    lasso_train_rmse.append(l_tr)\n", "    lasso_test_rmse.append(l_te)\n", "\n", "ridge_train_rmse = np.array(ridge_train_rmse)\n", "ridge_test_rmse = np.array(ridge_test_rmse)\n", "lasso_train_rmse = np.array(lasso_train_rmse)\n", "lasso_test_rmse = np.array(lasso_test_rmse)\n", "\n", "print(\"Ridge best test RMSE:\", float(ridge_test_rmse.min()), \"at lambda=\", float(lambdas[ridge_test_rmse.argmin()]))\n", "print(\"Lasso best test RMSE:\", float(lasso_test_rmse.min()), \"at lambda=\", float(lambdas[lasso_test_rmse.argmin()]))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Plots: RMSE vs $\\log_{10}(\\lambda)$\n", "One figure for Ridge, one for Lasso, training and testing curves together."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["logl = np.log10(lambdas)\n", "\n", "plt.figure()\n", "plt.plot(logl, ridge_train_rmse, marker='o', label='Train RMSE')\n", "plt.plot(logl, ridge_test_rmse, marker='s', label='Test RMSE')\n", "plt.xlabel('log10(lambda)')\n", "plt.ylabel('RMSE')\n", "plt.title('Ridge: RMSE vs log10(lambda)')\n", "plt.legend()\n", "plt.show()\n", "\n", "plt.figure()\n", "plt.plot(logl, lasso_train_rmse, marker='o', label='Train RMSE')\n", "plt.plot(logl, lasso_test_rmse, marker='s', label='Test RMSE')\n", "plt.xlabel('log10(lambda)')\n", "plt.ylabel('RMSE')\n", "plt.title('Lasso: RMSE vs log10(lambda)')\n", "plt.legend()\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---\n", "## Q4. Information & Cross-Entropy \u2014 KL Divergence under Drift\n", "We construct a discrete base distribution $p$ over indices $\\{0,1,\\dots,20\\}$ with a Gaussian shape centered at 10, then create shifted distributions $q_\\Delta$ with center moved by $\\Delta \\in \\{-8,-6,\\dots,8\\}$. We plot:\n", "1. The base $p$.\n", "2. A representative comparison of $p$ vs. $q_\\Delta$ (e.g., $\\Delta=5$).\n", "3. The KL divergence $D_{\\mathrm{KL}}(p\\Vert q_\\Delta)$ vs. $\\Delta$.\n", "\n", "All distributions are normalized; we add a small $\\varepsilon$ to avoid division by zero in the KL computation."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["idx = np.arange(21)\n", "center = 10\n", "sigma = 3.0\n", "\n", "p = np.exp(-0.5 * ((idx - center)/sigma)**2)\n", "p = p / p.sum()\n", "\n", "plt.figure()\n", "plt.stem(idx, p, use_line_collection=True)\n", "plt.xlabel('index')\n", "plt.ylabel('p(i)')\n", "plt.title('Base distribution p over {0..20}')\n", "plt.show()\n", "\n", "def shifted_q(delta: int) -> np.ndarray:\n", "    q_center = center + delta\n", "    q = np.exp(-0.5 * ((idx - q_center)/sigma)**2)\n", "    q = q / q.sum()\n", "    return q\n", "\n", "delta_example = 5\n", "q_ex = shifted_q(delta_example)\n", "\n", "plt.figure()\n", "plt.plot(idx, p, marker='o', label='p (center=10)')\n", "plt.plot(idx, q_ex, marker='s', label=f'q_\u0394 (center=10+{delta_example})')\n", "plt.xlabel('index')\n", "plt.ylabel('probability')\n", "plt.title('p vs q_\u0394 (representative drift)')\n", "plt.legend()\n", "plt.show()\n", "\n", "def kl_divergence(p: np.ndarray, q: np.ndarray, eps: float = 1e-12) -> float:\n", "    p_safe = np.clip(p, eps, 1.0)\n", "    q_safe = np.clip(q, eps, 1.0)\n", "    return float(np.sum(p_safe * np.log(p_safe / q_safe)))\n", "\n", "deltas = np.arange(-8, 9, 2)\n", "kls = []\n", "for d in deltas:\n", "    kls.append(kl_divergence(p, shifted_q(d)))\n", "kls = np.array(kls)\n", "\n", "plt.figure()\n", "plt.plot(deltas, kls, marker='o')\n", "plt.xlabel('\u0394 (drift)')\n", "plt.ylabel('DKL(p || q_\u0394)')\n", "plt.title('KL divergence vs drift \u0394')\n", "plt.show()\n", "\n", "for d, val in zip(deltas, kls):\n", "    print(f\"\u0394={d:+d} -> D_KL={val:.6f}\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---\n", "### Notes\n", "- Q2 uses standardized inputs with an explicit intercept term for the closed-form solution. Targets remain unscaled.\n", "- For Q2(c), the per-sample NLL is computed with a **fixed** $\\hat\\sigma^2$ estimated from the full training residuals, as requested.\n", "- Q3 scans $\\lambda$ on a wide log scale for both Ridge and Lasso. Lasso uses a higher `max_iter` for reliable convergence.\n", "- Q4 ensures distributions are normalized and guards KL against zero probabilities with a small $\\varepsilon$.\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.11"}}, "nbformat": 4, "nbformat_minor": 5}